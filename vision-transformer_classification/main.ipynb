{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTlkud2BfTOG"
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "!pip install datasets\n",
    "!pip install vit-pytorch\n",
    "!pip install x-transformers\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tH0Dp5hwfbMH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torchinfo\n",
    "import torchvision\n",
    "import tqdm\n",
    "from vit_pytorch.efficient import ViT  # 事前学習されていないバニラVisionTransformerモデルのようなもの\n",
    "import x_transformers  # Transformer層をモジュールにしたようなもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJ_1DXoMfg7R"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58sM33z9JGZY"
   },
   "source": [
    "**データ収集(今回はデータとして、HuggingFaceにある正解ラベル付きデータを使う)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E03hj6Ff78E"
   },
   "outputs": [],
   "source": [
    "# HuggingFaceにある犬猫写真分類の正解ラベル付きDatasetDictをロード\n",
    "hugging_face_dataset_dict = datasets.load_dataset(\"cats_vs_dogs\")\n",
    "# ロードしたDatasetDictからDataset(DatasetDictにあるDatasetはtrainのみ)を取得\n",
    "dataset = hugging_face_dataset_dict[\"train\"]\n",
    "# Dataset内のデータのタイプを確認\n",
    "print(dataset.features)\n",
    "# Dataset内のデータをシャッフル\n",
    "dataset_shuffle = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-80HhferlAt"
   },
   "outputs": [],
   "source": [
    "# Dataset内の最初の3つのデータの写真を確認\n",
    "for i in range(3):\n",
    "    display(dataset_shuffle[i][\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VQfXvJInzUG"
   },
   "outputs": [],
   "source": [
    "# Dataset内のデータを分割して、それぞれのDataset名がtrainとvalidationとtestのDatasetDictにする\n",
    "train_valid_test_dataset_dict = dataset_shuffle.train_test_split(test_size=0.1,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 stratify_by_column=\"labels\",  # stratify_by_columnに指定したカラムのデータが均等に分かれるように分割される\n",
    "                                                                 seed=42)\n",
    "test_dataset = train_valid_test_dataset_dict.pop(\"test\")\n",
    "train_valid_test_dataset_dict = train_valid_test_dataset_dict[\"train\"].train_test_split(test_size=0.2,\n",
    "                                                                                        shuffle=True,\n",
    "                                                                                        stratify_by_column=\"labels\",  # stratify_by_columnに指定したカラムのデータが均等に分かれるように分割される\n",
    "                                                                                        seed=42)\n",
    "valid_dataset = train_valid_test_dataset_dict.pop(\"test\")\n",
    "train_valid_test_dataset_dict[\"validation\"] = valid_dataset\n",
    "train_valid_test_dataset_dict[\"test\"] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1703051306443,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "XqVN2uDyK1u-",
    "outputId": "7f233c21-36cd-4408-a239-37ca79102ffb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 16855\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 4214\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 2341\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_test_dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcZ08Mt0K_D3"
   },
   "source": [
    "**データ拡張の準備**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GTUpdEgLOk0"
   },
   "outputs": [],
   "source": [
    "# trainをデータ拡張するCompose(torchvision.transformsの複数の処理を一つに纏めて、末尾の処理の出力を戻り値とする)インスタンスを作成\n",
    "train_argumentation = torchvision.transforms.Compose([torchvision.transforms.Resize(size=(224, 224)),  # 画像を指定の大きさにする # 単独で使う際はResizeクラスをインスタンス化してforwardと同じ使い方\n",
    "                                                      torchvision.transforms.RandomResizedCrop(size=(224, 224)),  # データ拡張(DataAugmentation)として、画像をランダムに切り抜いた後に指定の大きさにする\n",
    "                                                      torchvision.transforms.RandomHorizontalFlip(p=0.5),  # データ拡張として、画像をランダムに左右反転させる\n",
    "                                                      torchvision.transforms.ToTensor()])  # PILやnumpyを、(Channel, Height, Width)の形で、値は0.0～1.0のFloatTensorにする\n",
    "# validationをデータ拡張するComposeインスタンスを作成\n",
    "valid_argumentation = torchvision.transforms.Compose([torchvision.transforms.Resize(size=(256, 256)),\n",
    "                                                      torchvision.transforms.CenterCrop(size=(224, 224)),  # 画像の中央を指定の大きさで切り抜く\n",
    "                                                      torchvision.transforms.ToTensor()])\n",
    "# testをデータ拡張するComposeインスタンスを作成\n",
    "test_argumentation = torchvision.transforms.Compose([torchvision.transforms.Resize(size=(256, 256)),\n",
    "                                                     torchvision.transforms.CenterCrop(size=(224, 224)),\n",
    "                                                     torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6bWuKlnfbqF"
   },
   "source": [
    "**前処理(データ拡張も含む)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVMvPYJYfbNe"
   },
   "outputs": [],
   "source": [
    "# Datasetクラスを作成\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_data_list, label_value_list, argumentation_method=None):\n",
    "        self.img_data_list = img_data_list\n",
    "        self.label_value_list = label_value_list\n",
    "        self.argumentation_method = argumentation_method  # データ拡張のために作成したComposeインスタンスを入れる\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.img_data_list[idx]\n",
    "        argumentation_img_data = self.argumentation_method(img_data)  # インプットをPIL画像として、データ拡張のComposeインスタンスの処理を行う\n",
    "        label_value = self.label_value_list[idx]\n",
    "        return argumentation_img_data, label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1703051317113,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "5RznYuU6if2h",
    "outputId": "11d2c290-a5ce-49d4-9d67-fc333757da57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x348 at 0x7F8AE220FD90>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x321 at 0x7F8AE2EEF3D0>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=443x428 at 0x7F8AE2EEF580>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x300 at 0x7F8AE2EEF640>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F8AE2EEFB20>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x352 at 0x7F8AE2EEFBB0>,\n",
      " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=329x208 at 0x7F8AE2EEFCA0>]\n",
      "<class 'list'>\n",
      "[1, 0, 1, 1, 1, 0, 0]\n",
      "<class 'int'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(train_valid_test_dataset_dict[\"train\"][:7][\"image\"]))\n",
    "pprint.pprint(train_valid_test_dataset_dict[\"train\"][:7][\"image\"])\n",
    "print(type(train_valid_test_dataset_dict[\"train\"][:7][\"labels\"]))\n",
    "print(train_valid_test_dataset_dict[\"train\"][:7][\"labels\"])\n",
    "print(type(train_valid_test_dataset_dict[\"train\"][:7][\"labels\"][0]))\n",
    "print(train_valid_test_dataset_dict[\"train\"][:7][\"labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IRXuEsfsNCQ"
   },
   "outputs": [],
   "source": [
    "# train、validation、testデータ毎に写真と正解ラベルをそれぞれリストの形で取得\n",
    "train_img_data_list = train_valid_test_dataset_dict[\"train\"][:30][\"image\"]\n",
    "train_label_value_list = train_valid_test_dataset_dict[\"train\"][:30][\"labels\"]\n",
    "valid_img_data_list = train_valid_test_dataset_dict[\"validation\"][:6][\"image\"]\n",
    "valid_label_value_list = train_valid_test_dataset_dict[\"validation\"][:6][\"labels\"]\n",
    "test_img_data_list = train_valid_test_dataset_dict[\"test\"][:3][\"image\"]\n",
    "test_label_value_list = train_valid_test_dataset_dict[\"test\"][:3][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTcRaJDIuMKG"
   },
   "outputs": [],
   "source": [
    "# train、validation、testデータをそれぞれdataset化\n",
    "train_datasets = MyDataset(img_data_list=train_img_data_list,\n",
    "                           label_value_list=train_label_value_list,\n",
    "                           argumentation_method=train_argumentation)\n",
    "valid_datasets = MyDataset(img_data_list=valid_img_data_list,\n",
    "                           label_value_list=valid_label_value_list,\n",
    "                           argumentation_method=valid_argumentation)\n",
    "test_datasets = MyDataset(img_data_list=test_img_data_list,\n",
    "                          label_value_list=test_label_value_list,\n",
    "                          argumentation_method=test_argumentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMEusaQBvt2D"
   },
   "outputs": [],
   "source": [
    "# train、validation、testデータのdatasetをそれぞれdataloader化\n",
    "train_datasets_dataloader = torch.utils.data.DataLoader(dataset=train_datasets,\n",
    "                                                        batch_size=8,\n",
    "                                                        shuffle=True)\n",
    "valid_datasets_dataloader = torch.utils.data.DataLoader(dataset=valid_datasets,\n",
    "                                                        batch_size=8,\n",
    "                                                        shuffle=True)\n",
    "test_datasets_dataloader = torch.utils.data.DataLoader(dataset=test_datasets,\n",
    "                                                       batch_size=8,\n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1703051327618,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "KKpITTzl94ZL",
    "outputId": "1881e302-2fa4-47b2-de94-03ad960926d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_datasets))\n",
    "print(len(train_datasets_dataloader))\n",
    "print(len(valid_datasets))\n",
    "print(len(valid_datasets_dataloader))\n",
    "print(len(test_datasets))\n",
    "print(len(test_datasets_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z4h0j42zd2F"
   },
   "source": [
    "**VisionTransformerモデル**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLoF_sVr-fvg"
   },
   "outputs": [],
   "source": [
    "# VisionTransformerモデル(参考URL：https://qiita.com/zisui-sukitarou/items/d990a9630ff2c7f4abf2)\n",
    "nn_model = ViT(dim=128,  # Embedding層での次元数\n",
    "               image_size=224,  # 画像のサイズ(正方形の想定)\n",
    "               patch_size=7,  # 画像を切り出すパッチのサイズ(パッチ数は、image_size/patch_sizeの2乗になる)\n",
    "               num_classes=2,  # 出力層のパーセプトロン数(画像を分類する数)\n",
    "               channels=3,  # チャンネル数でRGBの場合は3 # ここまではEmbedding層の設定のイメージ\n",
    "               transformer=x_transformers.Encoder(dim=128,  # Transformer層での次元数 # ここからはTransformer層の設定のイメージ\n",
    "                                                  depth=12,  # Transformer層の深さ\n",
    "                                                  heads=8,  # Transformer層のMultiHeadAttentionの数\n",
    "                                                  ff_glu=True,  # FeedForwardingNetworkでの活性化関数でGLUを使うかどうか\n",
    "                                                  residual_attn=True)).to(device)  # ResidualAttentionBlockを使うかどうか # GPUへ\n",
    "# 損失関数\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "# 最適化アルゴリズム\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(),\n",
    "                             lr=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QzbF-4yAPsv"
   },
   "source": [
    "**学習**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5678a73aaeae485eabb7567f36c14d9f",
      "60fabb013d2146c096df6b87901117f3",
      "6958e27413ef434c87e34f7baf3fae84",
      "1a2bc54ab7454b14aceba8f7b4a0a0f2",
      "640f7e3764684328a61597d1adcb8c25",
      "f3baa1a6f141462682f74df230fa0964",
      "a861ec0a03074bd580773effa1124917",
      "d0452c7a0934484bbadd889b9667424e",
      "d4f0dca3051a40098a2ad4b32523b2d4",
      "8b25191ffa764ab489280dcd2ab7a6dc",
      "a166ab8c5ae74621bc80284a505d0a61",
      "1f0a8f87ac6e442985697f4783704192",
      "2f097f2a86044950bb6da57248eea31c",
      "11168bfc00c44216a215b960869b9def",
      "27f56fc3c1f94c2ba2021e995dbf76d0",
      "b5d1413cb618455fb3606cae7b3673c6",
      "6b9fec8937754aafa0204c7f4f7f5e95",
      "ab056201ebf44ae98892466ea803f6df",
      "b7058a67ba0741858b081bd02ed39ce8",
      "24aab071469e43f4b61c76cfd7cbd249",
      "655b2e86e919459cb13dcd93a8f49b3a",
      "641ac143bbe74e7aae86862ddde72da9",
      "813f2b875dfe40cea69d022b00a3416d",
      "e48667a40ced40bd8cf64cf5069b5d94",
      "5fcd7dd1c9d747b9a8c0b00268da2e74",
      "6e7980b997e945428aa6abce5c22f6f5",
      "d7f005399250410499652a917dcdbbc0",
      "63dff4ba28364570adfc58ac44f6a4d8",
      "b1d8118a12db4ae0bec21ee72b8a2e62",
      "466833718f804dc594b8171bd32a8b6f",
      "e03deb3a722648d894f025b2af393ed5",
      "2f17f8b5231347ad98f599650c16c1ad",
      "c5968959f9374f4bba8f4cbe64df1dbb",
      "234bdf4782aa4442ad57ad73f66bd1d9",
      "ac6a69dcc5a0468081aab1d28bd2fb1d",
      "d2448c9e42994944a8c204e222b71a45",
      "0d398ce45b5e403ab433a06aa45e3c01",
      "f83964c3609842dbab31e4a119ff6570",
      "df38a46ff2f343969fb4a084a8f598f2",
      "6999660ea5344cf9bc51cb7a22e6f976",
      "661e7409f9534f27b4374a9754c451dd",
      "ac8c3cc8bb04442ebdc55b689bbbaf0b",
      "dd48eca0ab6d4f0397e879d5534768fc",
      "da3a9dc9d01b47d9a7fd337b8fe25a2b",
      "3677e8f07f894a97848f1ef7b059e1ff",
      "2a1cbc70e582461b9c2568d63052364e",
      "1cdb433a485c41bbb25cbc9d223a0395",
      "b5b74ce821bf4540be88d59f95d2a88b",
      "f0294ce424824a89aafdc745ef039814",
      "38008038cd534e028cd2c6103a87a66e",
      "de14b9ac1f604d6099097aa1d27e2d84",
      "845bb6eef97b4a37819e59154fc39bea",
      "a64864ea502a4357a201e4d1d63d9408",
      "489d3d9cc0a847a2a04b740f4cfb71cd",
      "0c47fc442c504bde8b1c5eb1068c0aa8",
      "b2bccdb771d540ea9307c46d5a217903",
      "20dee7c7bb784c5cbc82a27a7eb030e6",
      "33caf70048a04e79b7154357acf13410",
      "51e63274d371407a86829ebc24284b73",
      "4bc25af17ba34900b0d20db7c133ea69",
      "0f391bd238264adc88e0d83f2b23b9cf",
      "9cad6a77d2e34b709f23aaf07c8c92d1",
      "123f730bc0274e9291cf673da2be1cb3",
      "06755e77c4d04da2bb6452132f759189",
      "7fcbb275346d4242a9b47de4fa2a96a8",
      "8e5e94ed8ac04ea1a70a53dae48d0613",
      "81693125f1114a1086341a6d76fd8c6c",
      "c7c4f4fcff9740b7b8b25b39b94e5ddf",
      "419f419047e14c52b039b5bf250eaecd",
      "75b2aadc7bc84ad39c3ead2baff98fc2",
      "34eba10eec65462ca0da426a0b4e2cd3",
      "8398395dad43496284c2c56f88aaf0c3",
      "0db5a318f00547729eee2e5d43e40713",
      "aec8fe77993744cd9dca45b89bb54254",
      "6c575f5211894700b77ddef2c237010d",
      "f2089a5742a64708ba94d88448c3e3e0",
      "78498dcd7a7341d8890b35643b32f039",
      "0b04a47f19504f6ab88b71a2bd523035",
      "677617b741f84c118f99c0e7700bc83e",
      "fcb842f5ee3244b08ca9d311f7cb3f89",
      "750f6d0db9004a158e647deba071943b",
      "be581c01f7ba40e390017b7f3b262744",
      "e7b3892093ad43d89d02475c5c3489c1",
      "5521a367918d421b8b6b2bee3e7a2a9b",
      "4d4842ca46094f59b523303daf1305fa",
      "e7df5411c12c4c7db1068f3695f798db",
      "ca7880e0a16f4ce3af152cc92733603e",
      "1c8352e0df52459e82f99e68ecaa2ffa",
      "1c7e27099d8044429bf6b72cf14c7ed2",
      "f254ecabea4046158fd319e5d65cdfa4",
      "c38c65675c0b40d080845e2b6bf79de5",
      "5f48b6ed2c39458094320b4ebcd2ae10",
      "c0775ea7e2084d3b86f2da86f9451319",
      "9b6c96a3f82f4f26b4a948139cf4d0f9",
      "b58d8dcdeca249c88eb3e15b35a30030",
      "1fe71887646a472bafd2e3762714ec1c",
      "8831b80b03064cb99a05299f27f5ba63",
      "586e968a36e54f9387101ff2a36f80a0",
      "daeafdd43d0a4a38bb10afac7322c151",
      "f3ed6cb7f03543ce978c48fa233bed4d",
      "17ef9c5a1ef1449a88b475e6433b538f",
      "127517bbd641440aa78c95c8d9866a0e",
      "174eabc78d23492380a18beec5738595",
      "167fed0583784c6790dc9ca9668c97b0",
      "ab2d5cdc0e11412c9b0dd66cdc8c261b",
      "f3c263d05b3641aaa6c4c4a7a53aa9e7",
      "dc3c80efb5d340a6820278ec22262b9b",
      "5cb2e337223a418a83228c2e333b8822",
      "bcd03b5cd4aa4c8dae74fde33e345f24",
      "ddaccf9a18994b61930d47260c7737f9"
     ]
    },
    "executionInfo": {
     "elapsed": 1138083,
     "status": "ok",
     "timestamp": 1703052577265,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "zzcY316zATXd",
    "outputId": "d4a81740-0a83-4dfd-dfc2-8af11224ac22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****1エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5678a73aaeae485eabb7567f36c14d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([0, 1, 1, 1, 0, 0, 1, 0])\n",
      "正解数： 4  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([0, 1, 1, 1, 1, 0, 1, 0])\n",
      "正解数： 5  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([0, 0, 0, 1, 1, 0, 1, 0])\n",
      "正解数： 3  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([1, 1, 0, 1, 0, 1])\n",
      "正解数： 4  /  6\n",
      "1エポック目 学習loss： 3.0810824036598206\n",
      "1エポック目 学習acc： 53.333333333333336 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0a8f87ac6e442985697f4783704192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1エポック目 検証loss： 0.7227637767791748\n",
      "1エポック目 検証acc： 33.33333333333333 %\n",
      "*****2エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813f2b875dfe40cea69d022b00a3416d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 0, 1, 1, 1])\n",
      "正解： tensor([0, 1, 1, 0, 0, 0, 1, 1])\n",
      "正解数： 5  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 1, 1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([1, 0, 0, 0, 1, 1, 0, 0])\n",
      "正解数： 2  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "正解： tensor([1, 0, 0, 1, 1, 1, 1, 0])\n",
      "正解数： 3  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 0])\n",
      "正解： tensor([1, 1, 1, 0, 1, 0])\n",
      "正解数： 2  /  6\n",
      "2エポック目 学習loss： 2.8474560379981995\n",
      "2エポック目 学習acc： 40.0 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234bdf4782aa4442ad57ad73f66bd1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2エポック目 検証loss： 0.6595127582550049\n",
      "2エポック目 検証acc： 66.66666666666666 %\n",
      "*****3エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3677e8f07f894a97848f1ef7b059e1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "正解： tensor([1, 1, 0, 1, 1, 1, 1, 0])\n",
      "正解数： 2  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "正解： tensor([0, 0, 0, 1, 1, 0, 0, 0])\n",
      "正解数： 5  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "正解： tensor([0, 0, 0, 1, 1, 0, 1, 0])\n",
      "正解数： 5  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([0, 0, 1, 0, 0, 1])\n",
      "正解： tensor([1, 1, 0, 1, 1, 1])\n",
      "正解数： 1  /  6\n",
      "3エポック目 学習loss： 2.8410053849220276\n",
      "3エポック目 学習acc： 43.333333333333336 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bccdb771d540ea9307c46d5a217903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3エポック目 検証loss： 0.6921827793121338\n",
      "3エポック目 検証acc： 50.0 %\n",
      "*****4エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81693125f1114a1086341a6d76fd8c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 0, 1, 1, 1, 1, 1])\n",
      "正解： tensor([1, 0, 1, 1, 1, 1, 0, 0])\n",
      "正解数： 5  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 1, 1, 1, 0, 0, 1])\n",
      "正解： tensor([0, 0, 0, 0, 1, 0, 1, 1])\n",
      "正解数： 4  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 0, 0, 1, 0, 1])\n",
      "正解： tensor([1, 1, 1, 0, 0, 1, 1, 1])\n",
      "正解数： 7  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([0, 0, 1, 0, 0, 1])\n",
      "正解数： 2  /  6\n",
      "4エポック目 学習loss： 2.7258434295654297\n",
      "4エポック目 学習acc： 60.0 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b04a47f19504f6ab88b71a2bd523035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4エポック目 検証loss： 0.7474479675292969\n",
      "4エポック目 検証acc： 33.33333333333333 %\n",
      "*****5エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7e27099d8044429bf6b72cf14c7ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 0, 1, 1, 1])\n",
      "正解： tensor([0, 1, 1, 0, 1, 1, 1, 0])\n",
      "正解数： 4  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([1, 0, 1, 1, 0, 0, 0, 0])\n",
      "正解数： 3  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 1, 1, 0, 1, 1, 1, 1])\n",
      "正解： tensor([0, 1, 1, 0, 0, 1, 0, 1])\n",
      "正解数： 6  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 1, 1])\n",
      "正解： tensor([1, 1, 0, 1, 0, 1])\n",
      "正解数： 4  /  6\n",
      "5エポック目 学習loss： 2.6493571996688843\n",
      "5エポック目 学習acc： 56.666666666666664 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ed6cb7f03543ce978c48fa233bed4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5エポック目 検証loss： 0.7656672596931458\n",
      "5エポック目 検証acc： 33.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(\"*****{a}エポック目*****\".format(a=epoch+1))\n",
    "    # 学習\n",
    "    epoch_loss_sum = 0\n",
    "    train_epoch_loss_sum_list = []\n",
    "    epoch_acc_sum = 0\n",
    "    epoch_accuracy = 0\n",
    "    train_epoch_accuracy_list = []\n",
    "    nn_model.train()\n",
    "    if os.path.isfile(\"./VisionTransformer_Classification_01.model\"):\n",
    "        nn_model.load_state_dict(torch.load(\"./VisionTransformer_Classification_01.model\"))\n",
    "    for img_data, label_value in tqdm.notebook.tqdm(train_datasets_dataloader):\n",
    "        print(img_data.shape)\n",
    "        img_data = img_data.to(device)  # GPUへ\n",
    "        label_value = label_value.to(device)  # GPUへ\n",
    "        output = nn_model(img_data)\n",
    "        loss = loss_f(output, label_value)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_sum = epoch_loss_sum + loss.item()\n",
    "        output_predict = torch.argmax(output, dim=1).to(\"cpu\")\n",
    "        print(\"予測：\", output_predict)\n",
    "        answer = label_value.to(\"cpu\")\n",
    "        print(\"正解：\", answer)\n",
    "        acc = torch.sum(output_predict == answer).item()  # スカラー値のtensorをitem()でintやfloatとして取得\n",
    "        print(\"正解数：\", acc, \" / \", len(output_predict))\n",
    "        epoch_acc_sum = epoch_acc_sum + acc\n",
    "    epoch_accuracy = epoch_acc_sum / len(train_datasets)\n",
    "    print(\"{a}エポック目 学習loss：\".format(a=epoch+1), epoch_loss_sum)\n",
    "    train_epoch_loss_sum_list.append(epoch_loss_sum)\n",
    "    print(\"{a}エポック目 学習acc：\".format(a=epoch+1), epoch_accuracy*100 , \"%\")\n",
    "    train_epoch_accuracy_list.append(epoch_accuracy)\n",
    "    # 検証\n",
    "    epoch_loss_sum = 0\n",
    "    valid_epoch_loss_sum_list = []\n",
    "    epoch_acc_sum = 0\n",
    "    epoch_accuracy = 0\n",
    "    valid_epoch_accuracy_list = []\n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img_data, label_value in tqdm.notebook.tqdm(valid_datasets_dataloader):\n",
    "            img_data = img_data.to(device)  # GPUへ\n",
    "            label_value = label_value.to(device)  # GPUへ\n",
    "            output = nn_model(img_data)\n",
    "            loss = loss_f(output, label_value)\n",
    "            epoch_loss_sum = epoch_loss_sum + loss.item()\n",
    "            output_predict = torch.argmax(output, dim=1).to(\"cpu\")\n",
    "            answer = label_value.to(\"cpu\")\n",
    "            acc = torch.sum(output_predict == label_value).item()  # スカラー値のtensorをitem()でintやfloatとして取得\n",
    "            epoch_acc_sum = epoch_acc_sum + acc\n",
    "        epoch_accuracy = epoch_acc_sum / len(valid_datasets)\n",
    "        print(\"{a}エポック目 検証loss：\".format(a=epoch+1), epoch_loss_sum)\n",
    "        valid_epoch_loss_sum_list.append(epoch_loss_sum)\n",
    "        print(\"{a}エポック目 検証acc：\".format(a=epoch+1), epoch_accuracy*100, \"%\")\n",
    "        valid_epoch_accuracy_list.append(epoch_accuracy)\n",
    "    # 学習で更新したパラメータを保存\n",
    "    torch.save(nn_model.state_dict(), \"./VisionTransformer_Classification_01.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13321,
     "status": "ok",
     "timestamp": 1702101259640,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "9FhYcpVlCJ00",
    "outputId": "0d092243-ad5f-41bd-d99c-e6849ebd70e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ViT                                                [8, 2]                    131,328\n",
       "├─Sequential: 1-1                                  [8, 1024, 128]            --\n",
       "│    └─Rearrange: 2-1                              [8, 1024, 147]            --\n",
       "│    └─LayerNorm: 2-2                              [8, 1024, 147]            294\n",
       "│    └─Linear: 2-3                                 [8, 1024, 128]            18,944\n",
       "│    └─LayerNorm: 2-4                              [8, 1024, 128]            256\n",
       "├─Encoder: 1-2                                     [8, 1025, 128]            --\n",
       "│    └─ModuleList: 2-5                             --                        --\n",
       "│    │    └─ModuleList: 3-1                        --                        262,400\n",
       "│    │    └─ModuleList: 3-2                        --                        198,016\n",
       "│    │    └─ModuleList: 3-3                        --                        262,400\n",
       "│    │    └─ModuleList: 3-4                        --                        198,016\n",
       "│    │    └─ModuleList: 3-5                        --                        262,400\n",
       "│    │    └─ModuleList: 3-6                        --                        198,016\n",
       "│    │    └─ModuleList: 3-7                        --                        262,400\n",
       "│    │    └─ModuleList: 3-8                        --                        198,016\n",
       "│    │    └─ModuleList: 3-9                        --                        262,400\n",
       "│    │    └─ModuleList: 3-10                       --                        198,016\n",
       "│    │    └─ModuleList: 3-11                       --                        262,400\n",
       "│    │    └─ModuleList: 3-12                       --                        198,016\n",
       "│    │    └─ModuleList: 3-13                       --                        262,400\n",
       "│    │    └─ModuleList: 3-14                       --                        198,016\n",
       "│    │    └─ModuleList: 3-15                       --                        262,400\n",
       "│    │    └─ModuleList: 3-16                       --                        198,016\n",
       "│    │    └─ModuleList: 3-17                       --                        262,400\n",
       "│    │    └─ModuleList: 3-18                       --                        198,016\n",
       "│    │    └─ModuleList: 3-19                       --                        262,400\n",
       "│    │    └─ModuleList: 3-20                       --                        198,016\n",
       "│    │    └─ModuleList: 3-21                       --                        262,400\n",
       "│    │    └─ModuleList: 3-22                       --                        198,016\n",
       "│    │    └─ModuleList: 3-23                       --                        262,400\n",
       "│    │    └─ModuleList: 3-24                       --                        198,016\n",
       "│    └─LayerNorm: 2-6                              [8, 1025, 128]            256\n",
       "├─Identity: 1-3                                    [8, 128]                  --\n",
       "├─Sequential: 1-4                                  [8, 2]                    --\n",
       "│    └─LayerNorm: 2-7                              [8, 128]                  256\n",
       "│    └─Linear: 2-8                                 [8, 2]                    258\n",
       "====================================================================================================\n",
       "Total params: 5,676,584\n",
       "Trainable params: 5,676,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 44.36\n",
       "====================================================================================================\n",
       "Input size (MB): 4.82\n",
       "Forward/backward pass size (MB): 2453.09\n",
       "Params size (MB): 22.18\n",
       "Estimated Total Size (MB): 2480.09\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの中身を表示\n",
    "torchinfo.summary(nn_model,\n",
    "                  input_size=(8, 3, 224, 224))  # モデルへ入力するデータの形状\n",
    "\n",
    "# 1024は、画像サイズが224×224の1枚の画像を、7×7のパッチに分割するので、224÷7=32から、32×32=1024個のパッチになり、それが時系列になるため\n",
    "# 128は、Embedding層での次元数を128で指定しているため"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ1Kn4V_xhye"
   },
   "source": [
    "**事前学習済みモデルを使ってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1702101348643,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "QbMYBd4nwlzT",
    "outputId": "e8b509bd-296a-411c-8305-90589dbf08cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bat_resnext26ts.ch_in1k',\n",
      " 'beit_base_patch16_224.in22k_ft_in22k',\n",
      " 'beit_base_patch16_224.in22k_ft_in22k_in1k',\n",
      " 'beit_base_patch16_384.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_224.in22k_ft_in22k',\n",
      " 'beit_large_patch16_224.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_384.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_512.in22k_ft_in22k_in1k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in1k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in22k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in1k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in22k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n",
      " 'botnet26t_256.c1_in1k']\n"
     ]
    }
   ],
   "source": [
    "# timmで事前学習済みのモデル名を取得して、その一部のモデル名を表示\n",
    "timm_pretrained_model_list = timm.list_models(pretrained=True)\n",
    "pprint.pprint(timm_pretrained_model_list[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5a8705f7fcc84709a935172c7a8fc266",
      "a91bbdd3b860457b944c06fddd24be29",
      "a90efa17839c44e187c176a55baf6da2",
      "d316cca767634041a349d0d0ccbc8817",
      "6a5ea8f4ed614e579e2f4f0631d0ad29",
      "04788462ab554af8ae992ccef8a25d86",
      "342694e481c248b0be7d98481ef754fa",
      "cbc0cac2179449b79cc6699d9e964177",
      "ca10f990be4e43fe9d79fc5f6ec27fbf",
      "45256d4b8f6c416fa38aa483201079ab",
      "90da24f280c8429eaca9fe339a36f9d7"
     ]
    },
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1702101355545,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "fTZRyka0ynGW",
    "outputId": "6b4578dd-07df-4d17-d46b-1ec29457862e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8705f7fcc84709a935172c7a8fc266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# モデルは、事前学習済みモデル「vit_small_patch16_224」を呼び出す\n",
    "nn_model = timm.create_model(model_name=\"vit_small_patch16_224\",\n",
    "                             pretrained=True,\n",
    "                             num_classes=2).to(device)\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(),\n",
    "                             lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "05e28b29ae6a4376b22e05733a11bdf9",
      "c558369b6375424086a04db9d69f337e",
      "53125c2f85cd43428a69a485491729e8",
      "a74429ce278a48fd8463b17ebd8a6c80",
      "9d9c2e016ab5454aaedb4dd96eed8590",
      "fea3c15d0cad4e87959133a615f7e110",
      "acfa7000ca13459fa2dc89134b091fca",
      "1ceaa2b0bda74d968efce7de597b168f",
      "3f2a782828d84d538167f148b1028b8d",
      "a4abad2393f24162b788df1c86c084f4",
      "7f555dc623dc4ab899085b558790456f",
      "ffaa3fdd273b444abe590bc533a68eeb",
      "7f41621be5dc4e24b1d91085deaa9b94",
      "544a53ea21a5431cbf03503c1d5a69de",
      "1f480f3184f64c03a88807ec718440a3",
      "c687e0e34b6d457ea97800407479b1ec",
      "3a7f84fe8c7940b1bb73af3f43b3f221",
      "b47e97b3b03f4b8985090e47a8b94144",
      "5c2753502492452c8b7c13d567280eb5",
      "f75288b08752467d90acec51a55b8abf",
      "3c3e732016d44b16ac12ad18c0a264f7",
      "f9e16af84ea24de89756aeadf2fea2f6",
      "33aca1daab254be585a808a8aa7afe9e",
      "1acc5884e60f4955bb8e39e5ba68be41",
      "29ff630a9c094885a8bcac58c4bf88c7",
      "2446d101c154427882d57ff99928f1e0",
      "cd8872630949440c8e5f1a1ac20b097e",
      "ca9b2ffd8f694915b6abe68eced282e6",
      "743139a4390c4994b5e3d3bdd9305a05",
      "46b2fcd59bd04cf0acb293d25b0e1151",
      "2ec2ba15f84246bfb7679039aa4698b8",
      "f80ee77122574906a7b2379abf03f565",
      "a1ba0986953e423cbcb29985dafc307d",
      "ec4027adfbb340ac8e4d38a7b208e16d",
      "82e721abe2c944c7ada8ffaa11555d11",
      "214e3069c85f4636840f2b38768c9f11",
      "8d270fa1bd4642c5be175eddfe2d9492",
      "be26db70b6a944b7973c37d7ebb63f89",
      "20875010c5f44a2ab884c73a98233e41",
      "37ea2ba860fc4331a806ddb6455fd6f1",
      "4dba54017bad4699a91813e6f7c3b3a0",
      "5d0fef0673ba480295a6f0f99e11bf56",
      "82bab80b3ef94e34bcc6351757e56b4b",
      "f9c7c8b6484c4fd58c09c502c4f879fd",
      "bd191143d3204f1db7fc5898dc3e630d",
      "385fe39151ec4ef89d0bcb266d8cfeaf",
      "04bea4887e10441689c41d5ede901f9e",
      "49a4879247f34ee882757ecc9e7215b0",
      "6ea2c63acab64e528ea74c5b4c6101d0",
      "ee78ddbe69004b8e965e379527d525a0",
      "9d9b2764c3344a77ada8f4c6607f950c",
      "b86c415772674d8c9011891784058394",
      "89f840b2967e4a4b83396cf6a3aae9b3",
      "1e5eb806700648d6998aa893fc3b39a0",
      "8ac072ee67c746f68d25540f2254a282",
      "b9231f643a07458db5903d683b50a73a",
      "3b12ec31329f448fa68fed0c3b9af1ac",
      "b5abd533115840dc821387e09ff018d0",
      "1b3360a5813e4a99b67231e5d8fecb30",
      "1641745b8b1b46aebb788ad810f319e9",
      "088c26a92fcf4037b26a143e17bd50ec",
      "b22846f030994f279d26bca0cac0876b",
      "c0c4a8c5ab9649999a77e4fb47760cde",
      "9c8475d5685c47b0967198244407d74d",
      "51d0f1d21ba2405ea8cfc3a69302f251",
      "548e7cdf4bb3478f919a763b9186acc8",
      "78e6f385b81449bca2f45b8db46ccc96",
      "dbdc823beca547af99febb4dc7c79fac",
      "06d77fd8a24545e689425b784520ff8a",
      "0d8e69608c6841778933854ad87e3c0f",
      "4fde8c3b1f4c44c2a3eed8fa8614bade",
      "12d03b8c58604ec3bd71ebb7f3a846ff",
      "b0a44bdafec741bb964998f5481bc1a3",
      "0231efec7f9b4e1aac4e926fd4e6c2ce",
      "6e848baf8f434953b6e197f73631d269",
      "cd52d51ce8f2430ebb7a19236b914a8b",
      "add5cef1af214e3e9a8d4831625de771",
      "eeceb681be3c4c92bd7ff2ce377559d3",
      "03ac9ab975194a7d93229bfbd8628605",
      "15aedb78caac47adbfe28c6c6fcbaf0e",
      "0c49d62c68124625ba6e2edcaf9a87cc",
      "3a638f40c54747a48890e3eb3494db79",
      "ab7ed8ff13654e4d9241a8f38de2ae05",
      "50270693df6149fcb2b319a69db98ece",
      "6b72750ae8ab4ad591ad52949aafad46",
      "75b59c32091247c4bdaf6383e05226ab",
      "513fdcc140ff492f940890e2950db760",
      "405020b9a15241cab81890c39179da73",
      "fe21948458a646a3ad13de8fd15f1b59",
      "e615c007d0434132a8afd8ea505bc3d3",
      "26bac3f17b9c40dda9b2503d925f687d",
      "89b24023fe764859a88dbadbb7e1219d",
      "e57a5f1723f340c1907348d5ea9308fc",
      "a9cd5e8eb75d4a1bb755bce035f22205",
      "6859fb27119f4e848eb4e0112dc0f505",
      "77a58d61917d4d5f9485da4b9ad92c58",
      "78a28d68b5e84dd691db2d2ab7ce7fe0",
      "d2fafac2ae2f40a28cc70facdc75c101",
      "0edb49fd81ff45cdb5db01f6a573e5bf",
      "6eade895bee646a7bfcf831d784bce94",
      "1b10ac68f17a4b379d7fc2ddec591c99",
      "f4a5e2846cee4772a6c43e372cff2a6f",
      "48ef88d0b32d4bd5aa09b3623d58d877",
      "2ba513cdc1544c688ae3503a2876f0c1",
      "f52902d78c6a4248ba5cad28120a1daa",
      "9b3f5cfcf31345cfaa35b353e34b7ce9",
      "d611204c577d408887f057d0e52334a8",
      "db795ff12a524a4e8458b8f6a7db8be8",
      "5978188dbf4e4820a9ad702fce828647",
      "236364a0ae8743fc993d0926195f29fb"
     ]
    },
    "executionInfo": {
     "elapsed": 66445,
     "status": "ok",
     "timestamp": 1702101507660,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "Q5InQcf8zeMR",
    "outputId": "bacc4f9c-4550-429e-e08a-f612c535f996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****1エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e28b29ae6a4376b22e05733a11bdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 1, 0, 0, 1, 0, 1, 1])\n",
      "正解： tensor([1, 1, 1, 0, 1, 1, 1, 1])\n",
      "正解数： 5  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 0, 0, 0, 0])\n",
      "正解： tensor([1, 1, 1, 1, 0, 0, 0, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 1, 0, 0, 0, 0, 1, 0])\n",
      "正解： tensor([0, 1, 0, 0, 1, 0, 1, 0])\n",
      "正解数： 7  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 0, 0, 1])\n",
      "正解： tensor([0, 1, 0, 0, 0, 1])\n",
      "正解数： 5  /  6\n",
      "1エポック目 学習loss： 0.9421654492616653\n",
      "1エポック目 学習acc： 83.33333333333334 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaa3fdd273b444abe590bc533a68eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1エポック目 検証loss： 0.21278314292430878\n",
      "1エポック目 検証acc： 100.0 %\n",
      "*****2エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aca1daab254be585a808a8aa7afe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
      "正解： tensor([1, 1, 1, 0, 1, 1, 0, 1])\n",
      "正解数： 7  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 1, 1, 0, 0, 0])\n",
      "正解： tensor([0, 0, 0, 1, 1, 0, 0, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 0, 1, 0, 0, 1, 0])\n",
      "正解： tensor([1, 0, 0, 1, 0, 0, 1, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 0, 1])\n",
      "正解： tensor([1, 1, 1, 1, 0, 1])\n",
      "正解数： 6  /  6\n",
      "2エポック目 学習loss： 0.5807420164346695\n",
      "2エポック目 学習acc： 96.66666666666667 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4027adfbb340ac8e4d38a7b208e16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2エポック目 検証loss： 0.24110375344753265\n",
      "2エポック目 検証acc： 83.33333333333334 %\n",
      "*****3エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd191143d3204f1db7fc5898dc3e630d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 1, 0, 0, 0, 1])\n",
      "正解： tensor([1, 1, 1, 1, 0, 0, 0, 1])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 1, 1, 0, 0, 0, 0])\n",
      "正解： tensor([0, 0, 1, 1, 0, 0, 0, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 1, 0, 1, 1, 1, 1])\n",
      "正解： tensor([1, 0, 1, 0, 1, 1, 1, 1])\n",
      "正解数： 8  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([0, 1, 1, 0, 0, 1])\n",
      "正解： tensor([0, 1, 1, 0, 0, 1])\n",
      "正解数： 6  /  6\n",
      "3エポック目 学習loss： 0.23251131735742092\n",
      "3エポック目 学習acc： 100.0 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9231f643a07458db5903d683b50a73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3エポック目 検証loss： 0.2430853396654129\n",
      "3エポック目 検証acc： 83.33333333333334 %\n",
      "*****4エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e6f385b81449bca2f45b8db46ccc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 1, 0, 1, 1, 1])\n",
      "正解： tensor([0, 0, 0, 1, 0, 1, 1, 1])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 0, 1, 1, 0, 0, 0])\n",
      "正解： tensor([1, 0, 0, 1, 1, 0, 0, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 1, 1, 0, 1, 1, 1, 0])\n",
      "正解： tensor([0, 1, 1, 0, 1, 1, 1, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([1, 1, 1, 0, 1, 0])\n",
      "正解： tensor([1, 1, 1, 0, 1, 0])\n",
      "正解数： 6  /  6\n",
      "4エポック目 学習loss： 0.20657029934227467\n",
      "4エポック目 学習acc： 100.0 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeceb681be3c4c92bd7ff2ce377559d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4エポック目 検証loss： 0.20055566728115082\n",
      "4エポック目 検証acc： 83.33333333333334 %\n",
      "*****5エポック目*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe21948458a646a3ad13de8fd15f1b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 0, 1, 1, 0, 1, 1])\n",
      "正解： tensor([0, 0, 0, 1, 1, 0, 1, 1])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([1, 0, 1, 1, 0, 1, 1, 0])\n",
      "正解： tensor([1, 0, 1, 1, 0, 1, 1, 0])\n",
      "正解数： 8  /  8\n",
      "torch.Size([8, 3, 224, 224])\n",
      "予測： tensor([0, 0, 1, 0, 1, 1, 1, 1])\n",
      "正解： tensor([0, 0, 1, 0, 1, 1, 1, 1])\n",
      "正解数： 8  /  8\n",
      "torch.Size([6, 3, 224, 224])\n",
      "予測： tensor([0, 0, 1, 0, 0, 1])\n",
      "正解： tensor([0, 0, 1, 0, 0, 1])\n",
      "正解数： 6  /  6\n",
      "5エポック目 学習loss： 0.0702239042147994\n",
      "5エポック目 学習acc： 100.0 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eade895bee646a7bfcf831d784bce94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5エポック目 検証loss： 0.1540786772966385\n",
      "5エポック目 検証acc： 83.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(\"*****{a}エポック目*****\".format(a=epoch+1))\n",
    "    # 学習(Fine Tuning)\n",
    "    epoch_loss_sum = 0\n",
    "    train_epoch_loss_sum_list = []\n",
    "    epoch_acc_sum = 0\n",
    "    epoch_accuracy = 0\n",
    "    train_epoch_accuracy_list = []\n",
    "    nn_model.train()\n",
    "    if os.path.isfile(\"./VisionTransformer_PreTrained_Classification_01.model\"):\n",
    "        nn_model.load_state_dict(torch.load(\"./VisionTransformer_PreTrained_Classification_01.model\"))\n",
    "    for img_data, label_value in tqdm.notebook.tqdm(train_datasets_dataloader):\n",
    "        print(img_data.shape)\n",
    "        img_data = img_data.to(device)  # GPUへ\n",
    "        label_value = label_value.to(device)  # GPUへ\n",
    "        output = nn_model(img_data)\n",
    "        loss = loss_f(output, label_value)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_sum = epoch_loss_sum + loss.item()\n",
    "        output_predict = torch.argmax(output, dim=1).to(\"cpu\")\n",
    "        print(\"予測：\", output_predict)\n",
    "        answer = label_value.to(\"cpu\")\n",
    "        print(\"正解：\", answer)\n",
    "        acc = torch.sum(output_predict == answer).item()  # スカラー値のtensorをitem()でintやfloatとして取得\n",
    "        print(\"正解数：\", acc, \" / \", len(output_predict))\n",
    "        epoch_acc_sum = epoch_acc_sum + acc\n",
    "    epoch_accuracy = epoch_acc_sum / len(train_datasets)\n",
    "    print(\"{a}エポック目 学習loss：\".format(a=epoch+1), epoch_loss_sum)\n",
    "    train_epoch_loss_sum_list.append(epoch_loss_sum)\n",
    "    print(\"{a}エポック目 学習acc：\".format(a=epoch+1), epoch_accuracy*100 , \"%\")\n",
    "    train_epoch_accuracy_list.append(epoch_accuracy)\n",
    "    # 検証\n",
    "    epoch_loss_sum = 0\n",
    "    valid_epoch_loss_sum_list = []\n",
    "    epoch_acc_sum = 0\n",
    "    epoch_accuracy = 0\n",
    "    valid_epoch_accuracy_list = []\n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img_data, label_value in tqdm.notebook.tqdm(valid_datasets_dataloader):\n",
    "            img_data = img_data.to(device)  # GPUへ\n",
    "            label_value = label_value.to(device)  # GPUへ\n",
    "            output = nn_model(img_data)\n",
    "            loss = loss_f(output, label_value)\n",
    "            epoch_loss_sum = epoch_loss_sum + loss.item()\n",
    "            output_predict = torch.argmax(output, dim=1).to(\"cpu\")\n",
    "            answer = label_value.to(\"cpu\")\n",
    "            acc = torch.sum(output_predict == label_value).item()  # スカラー値のtensorをitem()でintやfloatとして取得\n",
    "            epoch_acc_sum = epoch_acc_sum + acc\n",
    "        epoch_accuracy = epoch_acc_sum / len(valid_datasets)\n",
    "        print(\"{a}エポック目 検証loss：\".format(a=epoch+1), epoch_loss_sum)\n",
    "        valid_epoch_loss_sum_list.append(epoch_loss_sum)\n",
    "        print(\"{a}エポック目 検証acc：\".format(a=epoch+1), epoch_accuracy*100, \"%\")\n",
    "        valid_epoch_accuracy_list.append(epoch_accuracy)\n",
    "    # 学習(Fine Tuning)で更新したパラメータを保存\n",
    "    torch.save(nn_model.state_dict(), \"./VisionTransformer_PreTrained_Classification_01.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1702101565090,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "DJxH73p2CPhE",
    "outputId": "e36c6494-278c-4792-d453-685f463b7cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VisionTransformer                        [8, 2]                    76,032\n",
       "├─PatchEmbed: 1-1                        [8, 196, 384]             --\n",
       "│    └─Conv2d: 2-1                       [8, 384, 14, 14]          295,296\n",
       "│    └─Identity: 2-2                     [8, 196, 384]             --\n",
       "├─Dropout: 1-2                           [8, 197, 384]             --\n",
       "├─Identity: 1-3                          [8, 197, 384]             --\n",
       "├─Identity: 1-4                          [8, 197, 384]             --\n",
       "├─Sequential: 1-5                        [8, 197, 384]             --\n",
       "│    └─Block: 2-3                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-1               [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-2               [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-3                [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-4                [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-5               [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-6                     [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-7                [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-8                [8, 197, 384]             --\n",
       "│    └─Block: 2-4                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-9               [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-10              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-11               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-12               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-13              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-14                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-15               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-16               [8, 197, 384]             --\n",
       "│    └─Block: 2-5                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-17              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-18              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-19               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-20               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-21              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-22                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-23               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-24               [8, 197, 384]             --\n",
       "│    └─Block: 2-6                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-25              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-26              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-27               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-28               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-29              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-30                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-31               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-32               [8, 197, 384]             --\n",
       "│    └─Block: 2-7                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-33              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-34              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-35               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-36               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-37              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-38                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-39               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-40               [8, 197, 384]             --\n",
       "│    └─Block: 2-8                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-41              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-42              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-43               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-44               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-45              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-46                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-47               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-48               [8, 197, 384]             --\n",
       "│    └─Block: 2-9                        [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-49              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-50              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-51               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-52               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-53              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-54                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-55               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-56               [8, 197, 384]             --\n",
       "│    └─Block: 2-10                       [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-57              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-58              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-59               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-60               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-61              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-62                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-63               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-64               [8, 197, 384]             --\n",
       "│    └─Block: 2-11                       [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-65              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-66              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-67               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-68               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-69              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-70                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-71               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-72               [8, 197, 384]             --\n",
       "│    └─Block: 2-12                       [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-73              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-74              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-75               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-76               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-77              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-78                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-79               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-80               [8, 197, 384]             --\n",
       "│    └─Block: 2-13                       [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-81              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-82              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-83               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-84               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-85              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-86                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-87               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-88               [8, 197, 384]             --\n",
       "│    └─Block: 2-14                       [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-89              [8, 197, 384]             768\n",
       "│    │    └─Attention: 3-90              [8, 197, 384]             591,360\n",
       "│    │    └─Identity: 3-91               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-92               [8, 197, 384]             --\n",
       "│    │    └─LayerNorm: 3-93              [8, 197, 384]             768\n",
       "│    │    └─Mlp: 3-94                    [8, 197, 384]             1,181,568\n",
       "│    │    └─Identity: 3-95               [8, 197, 384]             --\n",
       "│    │    └─Identity: 3-96               [8, 197, 384]             --\n",
       "├─LayerNorm: 1-6                         [8, 197, 384]             768\n",
       "├─Identity: 1-7                          [8, 384]                  --\n",
       "├─Dropout: 1-8                           [8, 384]                  --\n",
       "├─Linear: 1-9                            [8, 2]                    770\n",
       "==========================================================================================\n",
       "Total params: 21,666,434\n",
       "Trainable params: 21,666,434\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 633.38\n",
       "==========================================================================================\n",
       "Input size (MB): 4.82\n",
       "Forward/backward pass size (MB): 648.73\n",
       "Params size (MB): 86.36\n",
       "Estimated Total Size (MB): 739.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの中身を表示\n",
    "torchinfo.summary(nn_model,\n",
    "                  input_size=(8, 3, 224, 224))  # モデルへ入力するデータの形状"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMQCgvTyboWSlIlS0r9sYk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
